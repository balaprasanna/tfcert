{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [ 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck' ]\n",
    "TRAIN_SUBSET = 10000 \n",
    "TEST_SUBSET = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_model(input_shape):\n",
    "    model = Sequential([\n",
    "         Conv2D(filters=16, input_shape=input_shape, kernel_size=(3, 3), activation='relu', name='conv_1'),\n",
    "         Conv2D(filters=8, input_shape=input_shape, kernel_size=(3, 3), activation='relu', name='conv_2'),\n",
    "         MaxPool2D(pool_size=(4, 4), name='pool_1'),\n",
    "         Flatten(name='flatten'), \n",
    "         Dense(units=32, activation='relu', name='dense_1'),\n",
    "         Dense(units=10, activation='softmax', name='dense_2')\n",
    "      ])\n",
    "    loss = SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_accuracy(model, X_test, y_test):\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('accuracy: {test_acc}'.format(test_acc=test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 28, 28, 8)         1160      \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                12576     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 14,514\n",
      "Trainable params: 14,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# X_train.shape = (32, 32, 3)\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "X_train = X_train[:TRAIN_SUBSET]\n",
    "y_train = y_train[:TRAIN_SUBSET]\n",
    "\n",
    "X_test = X_test[:TEST_SUBSET]\n",
    "y_test = y_test[:TEST_SUBSET]\n",
    "\n",
    "model = get_new_model(X_train[0].shape)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train set = ', 10000)\n"
     ]
    }
   ],
   "source": [
    "print('Train set = ',TRAIN_SUBSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('checkpoints/cifar_5000_{epoch:02d}_{val_loss}',\n",
    "                             save_weights_only=True, save_freq=5000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train = ', (10000, 32, 32, 3))\n",
      "('X_test = ', (1000, 32, 32, 3))\n"
     ]
    }
   ],
   "source": [
    "print('X_train = ', X_train.shape)\n",
    "print('X_test = ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 1.3763 - accuracy: 0.5112 - val_loss: 1.3996 - val_accuracy: 0.5020\n",
      "Epoch 2/3\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 1.3120 - accuracy: 0.5300 - val_loss: 1.3822 - val_accuracy: 0.5050\n",
      "Epoch 3/3\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 1.2623 - accuracy: 0.5502 - val_loss: 1.3324 - val_accuracy: 0.5350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa1075b3d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 100\n",
    "model.fit(x=X_train, y=y_train, \n",
    "          epochs=3, batch_size=bs,\n",
    "          steps_per_epoch=X_train.shape[0] / bs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          #callbacks=[ checkpoint ], \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
